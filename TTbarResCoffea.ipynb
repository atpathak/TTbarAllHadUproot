{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TTbarResCoffea` Notebook to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "This module must be run twice: \n",
    "   1. Make the mistag rate in the \"anti-tag and probe\" selection \n",
    "and the expectation in the signal region from MC,\n",
    "   1. Applies that mistag rate and the mod-mass procedure to the single-tag selection. \n",
    "\n",
    "These are all done in bins of\n",
    "b-tag categories (0, 1, $\\ge 2$) and rapidity ($|y| \\le 1.0$, $|y| > 1.0$).\n",
    "The signal region is two top-tagged jets. \n",
    "The background estimate is the single-tag selection weighted by the mistag rate from the\n",
    "\"anti-tag and probe\" region, with the mass of the weighted jet set to a random\n",
    "value from QCD MC in the 1-ttag region. \n",
    "\n",
    "\n",
    "The preselection is:\n",
    "- AK4-based $H_{T} > 1100$ GeV (to be on the trigger plateau). \n",
    "- $\\ge 2$ AK8 jets with AK8 $p_{T} > 400$ GeV and $|y| < 2.5$, loose jet ID applied from matched AK4 jets\n",
    "\n",
    "The 1-tag selection adds:\n",
    "- $\\ge 1$ AK8 jet with top tagging applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The anti-tag selection is disjoint from the 1-tag selection:\n",
    "- $\\ge 1$ AK8 jet with top tagging VETO applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The 2-tag selection is:\n",
    "- $\\ge 2$ AK8 jets with top tagging applied to both leading jets. \n",
    "\n",
    "\n",
    "The ttbar candidate mass assumes the two leading top-tagged jets are the top quarks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@TTbarResAnaHadronic Package to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "\"\"\"\n",
    "class TTbarResProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, htCut=1100., minMSD=105., maxMSD=210., tau32Cut=0.7, ak8PtMin=400., bdisc=0.7,\n",
    "                writePredDist=True,isData=True,year=2019):\n",
    "        \n",
    "        self.htCut = htCut\n",
    "        self.minMSD = minMSD\n",
    "        self.maxMSD = maxMSD\n",
    "        self.tau32Cut = tau32Cut\n",
    "        self.ak8PtMin = ak8PtMin\n",
    "        self.bdisc = bdisc\n",
    "        self.writePredDist = writePredDist\n",
    "        self.writeHistFile = True\n",
    "        self.isData = isData\n",
    "        self.year=year\n",
    "        \n",
    "        self.btagcats = [\"0b\", \"1b\", \"2b\"]   # 0, 1, >=2 btags\n",
    "        self.ycats = ['cen', 'fwd']          # Central and forward\n",
    "        # Combine categories like \"0bcen\", \"0bfwd\", etc:\n",
    "        self.anacats = [ b+y for b,y in itertools.product( self.btagcats, self.ycats) ]\n",
    "        self.anacats += ['pretag']\n",
    "        print(self.anacats)\n",
    "        \n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        cats_axis = hist.Cat(\"anacat\", \"Analysis Category\")\n",
    "        \n",
    "        ht_axis = hist.Bin(\"h_ak4ht\", r\"AK4 Jet H_{T} [GeV]\", 50, 0, 5000)\n",
    "        jetmass_axis = hist.Bin(\"jetmass\", r\"Jet $m$ [GeV]\", 50, 0, 500)\n",
    "        jetpt_axis = hist.Bin(\"jetpt\", r\"Jet $p_{T}$ [GeV]\", 50, 0, 5000)\n",
    "        jetn3b1_axis = hist.Bin(\"n3b1\", r\"Jet N3\", 50, 0, 1)\n",
    "        ttbarmass_axis = hist.Bin(\"ttbarmass\", r\"$m_{t\\bar{t}}$ [GeV]\", 50, 0, 5000)\n",
    "        \n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'h_ak4ht'  : hist.Hist(\"Counts\", dataset_axis, cats_axis, ht_axis),\n",
    "            'ttbarmass': hist.Hist(\"Counts\", dataset_axis, cats_axis, ttbarmass_axis),\n",
    "            'jetmass':   hist.Hist(\"Counts\", dataset_axis, cats_axis, jetmass_axis),\n",
    "            'jetpt':     hist.Hist(\"Counts\", dataset_axis, cats_axis, jetpt_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int),\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "        output = self.accumulator.identity()\n",
    "\n",
    "        dataset = df['dataset']\n",
    "        FatJets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nFatJet'],\n",
    "            pt=df['FatJet_pt'],\n",
    "            eta=df['FatJet_eta'],\n",
    "            phi=df['FatJet_phi'],\n",
    "            mass=df['FatJet_mass'],\n",
    "            msoftdrop=df['FatJet_msoftdrop'],\n",
    "            jetId=df['FatJet_jetId'],\n",
    "            tau1=df['FatJet_tau1'],\n",
    "            tau2=df['FatJet_tau2'],\n",
    "            tau3=df['FatJet_tau3'],\n",
    "            tau4=df['FatJet_tau4'],\n",
    "            n3b1=df['FatJet_n3b1'],\n",
    "            btagDeepB=df['FatJet_btagDeepB']\n",
    "            )\n",
    "        \n",
    "        #weight = JaggedArray.fromcounts(\n",
    "        #    np.ones_like(df['Generator_binvar'],dtype=int),\n",
    "        #    df['Generator_weight']\n",
    "        #)\n",
    "        evtweights = df[\"Generator_weight\"].reshape(-1, 1).flatten()\n",
    "        output['cutflow']['all events'] += FatJets.size\n",
    "        \n",
    "        jet_id = (FatJets.jetId > 0)\n",
    "        FatJets = FatJets[jet_id]\n",
    "        output['cutflow']['jet id'] += jet_id.any().sum()\n",
    "        \n",
    "        jetkincut_index = (FatJets.pt > self.ak8PtMin) & (abs(FatJets.eta) < 2.5)\n",
    "        FatJets = FatJets[ jetkincut_index ]\n",
    "        \n",
    "        oneFatJet = (FatJets.counts >=1)\n",
    "        output['cutflow']['one FatJet'] += oneFatJet.sum()\n",
    "        \n",
    "        twoFatJets = (FatJets.counts >= 2)\n",
    "        output['cutflow']['two FatJets'] += twoFatJets.sum()\n",
    "\n",
    "        FatJets = FatJets[twoFatJets]\n",
    "        evtweights = evtweights[twoFatJets]\n",
    "        \n",
    "        index = JaggedArray.fromcounts(np.ones(len(FatJets), dtype='i'), np.random.randint(2, size=len(FatJets)))\n",
    "        jet0 = FatJets[index]\n",
    "        jet1 = FatJets[1 - index]\n",
    "        \n",
    "        ttbarcands = jet0.cross(jet1) #FatJets[:,0:2].distincts()\n",
    "        \n",
    "        oneTTbar = (ttbarcands.counts >= 1)\n",
    "        output['cutflow']['>= one oneTTbar'] += oneTTbar.sum()\n",
    "        ttbarcands = ttbarcands[oneTTbar]\n",
    "        evtweights = evtweights[oneTTbar]\n",
    "        FatJets = FatJets[oneTTbar]\n",
    "\n",
    "        dPhiCut = (ttbarcands.i0.p4.delta_phi(ttbarcands.i1.p4) > 2.1).flatten()\n",
    "        output['cutflow']['dPhi > 2.1'] += dPhiCut.sum()\n",
    "        ttbarcands = ttbarcands[dPhiCut]\n",
    "        evtweights = evtweights[dPhiCut]\n",
    "        FatJets = FatJets[dPhiCut]\n",
    "        \n",
    "        ttbarmass = ttbarcands.p4.sum().mass.flatten()    \n",
    "        \n",
    "        output['ttbarmass'].fill(dataset=dataset, anacat='pretag', \n",
    "                            ttbarmass=tttbarmass,\n",
    "                            weight=evtweights.flatten())\n",
    "        \n",
    "        # Now get the analysis categories. \n",
    "        # They are (central, forward)   cross   (0b,1b,>=2b)\n",
    "        cen = abs(ttbarcands.i0.p4.y - ttbarcands.i1.p4.y) < 1.0\n",
    "        fwd = np.logical_not(cen)\n",
    "        \n",
    "        taucut_i0 = np.where( ttbarcands.i0.tau2 > 0, ttbarcands.i0.tau3 / ttbarcands.i0.tau2, 0)\n",
    "        taucut_i1 = np.where( ttbarcands.i1.tau2 > 0, ttbarcands.i1.tau3 / ttbarcands.i1.tau2, 0)\n",
    "        \n",
    "        mcut_i0 = 110. < ttbarcands.i0.msoftdrop < 250.\n",
    "        mcut_i1 = 110. < ttbarcands.i1.msoftdrop < 250.\n",
    "        \n",
    "        ttag_i0 = (taucut_i0) & (mcut_i0)\n",
    "        ttag_i1 = (taucut_i1) & (mcut_i1)\n",
    "        tantitag = (~taucut_i0) & (mcut_i0)   # always anti-tagging \"jet 0\"\n",
    "        \n",
    "        ttag0 = np.logical_not(ttag_i0) & np.logical_not(ttag_i1)\n",
    "        ttag1 = ttag_i0 ^ ttag_i1\n",
    "        ttag2 = ttag_i0 & ttag_i1\n",
    "        \n",
    "        btag_i0 = (ttbarcands.i0.btagDeepB > 0.7)\n",
    "        btag_i1 = (ttbarcands.i1.btagDeepB > 0.7)\n",
    "        \n",
    "        btag0 = np.logical_not(btag_i0) & np.logical_not(btag_i1)\n",
    "        btag1 = btag_i0 ^ btag_i1\n",
    "        btag2 = btag_i0 & btag_i1\n",
    "        \n",
    "        for ireg in [cen,fwd]:\n",
    "            for btag in [btag0,btag1,btag2]:\n",
    "                for ttag in [antitag,ttag0,ttag1,ttag2]:\n",
    "                    cat = (ireg & btag & ttag).flatten()\n",
    "\n",
    "        \n",
    "                    output['cutflow']['0bcen'] += cat0.sum()        \n",
    "                    output['ttbarmass'].fill(dataset=dataset, anacat='0bcen', \n",
    "                                ttbarmass=ttbarmass[cat0],\n",
    "                                weight=evtweights[cat0].flatten())\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prefix = '/mnt/data/cms/'\n",
    "#prefix = 'root://cmsxrootd.fnal.gov/'\n",
    "\n",
    "f= open(\"QCD_Pt-15to7000_TuneCP5_Flat_13TeV_pythia8.txt\")\n",
    "lines = f.readlines()\n",
    "files = [prefix + line.rstrip() for line in lines]\n",
    "fileset = {\n",
    "    'QCD':files[0:2] # QCD_Pt-15to7000_TuneCP5_Flat_13TeV_pythia8\n",
    "    #'ZZ to 4mu': [\n",
    "    #    'data/ZZTo4mu.root'\n",
    "    #]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'QCD': ['/mnt/data/cms//store/mc/RunIIFall17NanoAODv5/QCD_Pt-15to7000_TuneCP5_Flat_13TeV_pythia8/NANOAODSIM/PU2017_12Apr2018_Nano1June2019_102X_mc2017_realistic_v7-v1/40000/E453C056-E127-B541-B545-FF5F4348FBBF.root', '/mnt/data/cms//store/mc/RunIIFall17NanoAODv5/QCD_Pt-15to7000_TuneCP5_Flat_13TeV_pythia8/NANOAODSIM/PU2017_12Apr2018_Nano1June2019_102X_mc2017_realistic_v7-v1/40000/03DA78CB-8064-2C48-82D0-9CC7A13DBB44.root']}\n"
     ]
    }
   ],
   "source": [
    "print(fileset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0bcen', '0bfwd', '1bcen', '1bfwd', '2bcen', '2bfwd', 'pretag']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cfc59a44a0408d90d2ee69809f43af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Preprocessing', max=1, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce9a63f816746b0a165f5b496bf3ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing', max=5, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'h_ak4ht': <Hist (dataset,anacat,h_ak4ht) instance at 0x7f956df3f2b0>, 'ttbarmass': <Hist (dataset,anacat,ttbarmass) instance at 0x7f956df3f470>, 'jetmass': <Hist (dataset,anacat,jetmass) instance at 0x7f956df3f5f8>, 'jetpt': <Hist (dataset,anacat,jetpt) instance at 0x7f956df3fe80>, 'cutflow': defaultdict(<class 'int'>, {'all events': 1887376, 'jet id': 1030564, 'one FatJet': 467006, 'two FatJets': 364275, '>= one oneTTbar': 364275, 'dPhi > 2.1': 182373, '0bcen': 92, '0bfwd': 177733, '1bcen': 2, '1bfwd': 4501, '2bcen': 0, '2bfwd': 45})}\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "        \n",
    "\n",
    "\n",
    "output = processor.run_uproot_job(fileset,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=TTbarResProcessor(),\n",
    "                                  executor=processor.futures_executor,\n",
    "                                  executor_args={'workers': 1, 'flatten': True},\n",
    "                                  chunksize=500000#,maxchunks=10\n",
    "                                 )\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_fill_opts = {'alpha': 0.8, 'edgecolor':(0,0,0,.5)}\n",
    "stack_error_opts = {'label':'Stat. Unc.', 'hatch':'///', 'facecolor':'none', 'edgecolor':(0,0,0,.5), 'linewidth': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = hist.plotgrid(output['ttbarmass'], row=\"anacat\", overlay=\"dataset\", stack=True,\n",
    "                                  #fill_opts=stack_fill_opts,\n",
    "                                  #error_opts=stack_error_opts,\n",
    "                                 )\n",
    "plt.yscale(\"log\")\n",
    "for iax in ax.flatten():\n",
    "    iax.autoscale(axis='y')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Events/s:\", output['cutflow']['all events']/elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in output['cutflow'].items():\n",
    "    print( '%20s : %12d' % (i,j) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mapping = {\n",
    "#    'QCD': ['QCD'],\n",
    "#}\n",
    "#output['ttbarmass'].group(\"dataset\", hist.Cat(\"dataset\", \"dataset\"), mapping)\n",
    "#hist_noDS = output['ttbarmass_pretag'].integrate('dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
